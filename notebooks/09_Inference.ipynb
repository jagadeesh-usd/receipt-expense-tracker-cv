{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Expense Extraction - Receipt Parsing Using YOLO and OCR\n",
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12095,
     "status": "ok",
     "timestamp": 1765045802131,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "DZqkEc8DprT0",
    "outputId": "94912927-064b-446b-e02c-4e934e8202b8"
   },
   "outputs": [],
   "source": [
    "# Install Dependencies\n",
    "!pip install ultralytics pytesseract\n",
    "# !sudo apt-get install tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8766,
     "status": "ok",
     "timestamp": 1765045812668,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "ebnboSmpp0zl",
    "outputId": "7dc43051-3ce5-440a-dfaa-6b03caff60a8"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38210,
     "status": "ok",
     "timestamp": 1765045866875,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "kp_R30Ktzsfp",
    "outputId": "e48f727d-a98f-43ff-f0c0-d5937afcb0ea"
   },
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    # Mount Google Drive (for Colab)\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Set DATA_PATH for Google Drive\n",
    "    DATA_PATH = Path('/content/drive/MyDrive/data')\n",
    "else:\n",
    "    # Set DATA_PATH for local environment\n",
    "    DATA_PATH = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2018,
     "status": "ok",
     "timestamp": 1765045870953,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "Wbjp7mqYp31m"
   },
   "outputs": [],
   "source": [
    "# Load YOUR trained model\n",
    "\n",
    "# model_path = DATA_PATH / \"models/yolo_receipts/weights/best.pt\"\n",
    "# model_path = DATA_PATH / \"models/yolo_receipts_small/weights/best.pt\"\n",
    "model_path = DATA_PATH / \"models/yolo_receipts_highres_nano/weights/best.pt\"\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765045875204,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "77aXe7SM0Bs3"
   },
   "outputs": [],
   "source": [
    "# ADAPTIVE PREPROCESSING\n",
    "\n",
    "def clean_crop_vendor(crop_img):\n",
    "    \"\"\"Gentle cleaning for Logos (Grayscale + Median Blur)\"\"\"\n",
    "    if len(crop_img.shape) == 3: gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "    else: gray = crop_img\n",
    "    gray = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    return cv2.medianBlur(gray, 3)\n",
    "\n",
    "def clean_crop_numeric(crop_img):\n",
    "    \"\"\"Aggressive cleaning for Numbers (Adaptive Threshold)\"\"\"\n",
    "    if len(crop_img.shape) == 3: gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "    else: gray = crop_img\n",
    "    gray = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    return cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 10)\n",
    "\n",
    "def preprocess_full_page(original_img):\n",
    "    \"\"\"\n",
    "    UNIVERSAL CLEANER: Handles both Scans (SROIE) and Mobile Photos.\n",
    "    1. Removes Scanner Borders.\n",
    "    2. Adaptive Thresholding (Best for text).\n",
    "    \"\"\"\n",
    "    # 1. Convert to Gray\n",
    "    if len(original_img.shape) == 3:\n",
    "        gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = original_img\n",
    "\n",
    "    # 2. Resize (Standardize)\n",
    "    h, w = gray.shape\n",
    "    scale = 1000 / h\n",
    "    gray = cv2.resize(gray, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 3. Gaussian Blur (Kill sensor noise)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # 4. Morphological Open (Remove thin lines/noise)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2,2))\n",
    "    gray = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # 5. Adaptive Thresholding (The Robust Standard)\n",
    "    # We use a large block size (31) to handle shadows if they exist,\n",
    "    # but it works perfectly on flat white scans too.\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        31, 10\n",
    "    )\n",
    "\n",
    "    # 6. BORDER REMOVAL (Crucial for Scans)\n",
    "    # Finds the largest connected component (the receipt) and blacks out the rest\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        largest_cnt = max(contours, key=cv2.contourArea)\n",
    "        mask = np.zeros_like(thresh)\n",
    "        cv2.drawContours(mask, [largest_cnt], -1, 255, -1)\n",
    "        # Apply mask: Keep only the receipt, make everything else white\n",
    "        result = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "        # Invert mask to make background white (Tesseract loves white backgrounds)\n",
    "        background = cv2.bitwise_not(mask)\n",
    "        result = cv2.add(result, background)\n",
    "        return result\n",
    "\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1765045879569,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "_n5auAgWpzJ2"
   },
   "outputs": [],
   "source": [
    "# UNIVERSAL FALLBACK LOGIC\n",
    "\n",
    "def fallback_find_total(text):\n",
    "    \"\"\"\n",
    "    Finds currency.\n",
    "    IMPROVEMENT: Uses \\b to force stop after 2 decimals.\n",
    "    Handles 9.00, 1,200.50, 9,00 (European style)\n",
    "    \"\"\"\n",
    "    # Regex:\n",
    "    # \\d{1,3}       -> 1 to 3 digits\n",
    "    # (?:[.,]\\d{3})* -> Optional thousands separators\n",
    "    # [.,]          -> Decimal point (dot or comma)\n",
    "    # \\d{2}         -> EXACTLY two decimals\n",
    "    # \\b            -> Word boundary (Stops 9.006 from becoming 9.006)\n",
    "    pattern = r'(\\d{1,3}(?:[.,]\\d{3})*[.,]\\d{2})\\b'\n",
    "\n",
    "    matches = re.findall(pattern, text)\n",
    "    if not matches: return None\n",
    "\n",
    "    try:\n",
    "        # Clean standard: replace , with . if it looks like a decimal\n",
    "        # Heuristic: The largest number is usually the Total\n",
    "        clean_values = []\n",
    "        for m in matches:\n",
    "            # Normalize 1,200.00 -> 1200.00\n",
    "            # Normalize 9,00 -> 9.00\n",
    "            val = m.replace(',', '.')\n",
    "            # Fix double dots if any\n",
    "            if val.count('.') > 1: val = val.replace('.', '', val.count('.')-1)\n",
    "            clean_values.append(float(val))\n",
    "\n",
    "        return \"{:.2f}\".format(max(clean_values))\n",
    "    except:\n",
    "        return matches[-1]\n",
    "\n",
    "def fallback_find_vendor(text):\n",
    "    \"\"\"\n",
    "    Heuristic: Vendor is the first SIGNIFICANT line.\n",
    "    IMPROVEMENT: Skips lines that are too short (< 4 chars).\n",
    "    \"\"\"\n",
    "    # Split into lines and remove empty ones\n",
    "    lines = [line.strip() for line in text.split('\\n') if len(line.strip()) > 0]\n",
    "\n",
    "    blacklist = [\"welcome\", \"receipt\", \"tax invoice\", \"gst\", \"tel\", \"fax\", \"website\", \"email\"]\n",
    "\n",
    "    for line in lines[:6]: # Check top 6 lines\n",
    "        # Rule 1: Must be longer than 3 chars (\"NH\" -> Skip)\n",
    "        if len(line) < 4: continue\n",
    "\n",
    "        # Rule 2: Must not contain blacklist words\n",
    "        if not any(b in line.lower() for b in blacklist):\n",
    "            # Rule 3: Must generally look like a name (mostly letters)\n",
    "            # (Optional check to avoid pure numbers being picked as vendor)\n",
    "            if any(c.isalpha() for c in line):\n",
    "                return line\n",
    "    return None\n",
    "\n",
    "def get_full_page_text(original_img):\n",
    "    \"\"\"Debug wrapper for OCR\"\"\"\n",
    "    print(\"   âš ï¸ Running Full Page OCR Safety Net...\")\n",
    "    processed = preprocess_full_page(original_img)\n",
    "\n",
    "    # DEBUG: See what the safety net sees!\n",
    "    plt.figure(figsize=(6,6)); plt.imshow(processed, cmap='gray'); plt.title(\"Safety Net Input\"); plt.show()\n",
    "\n",
    "    text = pytesseract.image_to_string(processed, config='--psm 3')\n",
    "\n",
    "    # DEBUG: Print the text to console so you can see why it failed\n",
    "    # print(f\"--- FULL PAGE TEXT DUMP ---\\n{text}\\n---------------------------\")\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def fallback_find_date(text):\n",
    "    \"\"\"Finds date patterns in full text\"\"\"\n",
    "    # Matches: 25/12/2018, 2018-12-25, 25 DEC 2018\n",
    "    pattern = r'(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{4}[/-]\\d{1,2}[/-]\\d{1,2}|\\d{1,2}\\s(?:JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)[a-z]*\\s\\d{2,4})'\n",
    "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "    return matches[0] if matches else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1765045883960,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "UYQmMeLZefVN"
   },
   "outputs": [],
   "source": [
    "# MAIN INFERENCE PIPELINE\n",
    "\n",
    "def run_scanner(image_path):\n",
    "    print(f\"\\n--- ðŸ“¸ Scanning: {image_path.name} ---\")\n",
    "\n",
    "    # 1. VISUAL DETECTION (YOLO)\n",
    "    results = model.predict(image_path, conf=0.10, verbose=False)\n",
    "    result = results[0]\n",
    "    original_img = cv2.imread(str(image_path))\n",
    "    display_img = cv2.cvtColor(original_img.copy(), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    extracted_data = {}\n",
    "\n",
    "    # 2. PROCESS YOLO HITS\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        cls_id = int(box.cls[0])\n",
    "        label = model.names[cls_id]\n",
    "\n",
    "        # Crop & Clean\n",
    "        h, w, _ = original_img.shape\n",
    "        crop = original_img[max(0, y1-5):min(h, y2+5), max(0, x1-5):min(w, x2+5)]\n",
    "        if crop.size == 0: continue\n",
    "\n",
    "        if label in ['company', 'vendor']:\n",
    "            final_crop = clean_crop_vendor(crop)\n",
    "            config = '--psm 6'\n",
    "        else:\n",
    "            final_crop = clean_crop_numeric(crop)\n",
    "            config = '--psm 7 -c tessedit_char_whitelist=0123456789./:-RM'\n",
    "\n",
    "        text = pytesseract.image_to_string(final_crop, config=config).strip()\n",
    "        if label == 'total': text = text.replace(\"RP\", \"RM\").replace(\"Rm\", \"RM\")\n",
    "\n",
    "        # Store (Keep first detection)\n",
    "        if label not in extracted_data:\n",
    "            extracted_data[label] = text\n",
    "\n",
    "        # Visualization\n",
    "        cv2.rectangle(display_img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "        cv2.putText(display_img, f\"{label}: {text}\", (x1, y1-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # UNIVERSAL SAFETY NET (Check ALL fields)\n",
    "    required_fields = ['vendor', 'date', 'total']\n",
    "\n",
    "    # Check if we are missing ANY field\n",
    "    # (Note: YOLO might name vendor 'company', normalize this)\n",
    "    if 'company' in extracted_data: extracted_data['vendor'] = extracted_data.pop('company')\n",
    "\n",
    "    missing_fields = [f for f in required_fields if f not in extracted_data]\n",
    "\n",
    "    if missing_fields:\n",
    "        print(f\"   âš ï¸ Missing fields: {missing_fields}. Engaging Fallback...\")\n",
    "\n",
    "        # Run OCR ONCE on full page\n",
    "        full_text = get_full_page_text(original_img)\n",
    "        print(full_text)\n",
    "\n",
    "        if 'date' in missing_fields:\n",
    "            val = fallback_find_date(full_text)\n",
    "            if val: extracted_data['date'] = val\n",
    "\n",
    "        if 'total' in missing_fields:\n",
    "            val = fallback_find_total(full_text)\n",
    "            if val: extracted_data['total'] = val\n",
    "\n",
    "        if 'vendor' in missing_fields:\n",
    "            val = fallback_find_vendor(full_text)\n",
    "            if val: extracted_data['vendor'] = val\n",
    "\n",
    "    # 4. DISPLAY\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(display_img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"YOLO + Hybrid Fallback\", fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n--- ðŸ§¾ EXTRACTED DATA ---\")\n",
    "    for k, v in extracted_data.items():\n",
    "        print(f\"  {k.upper()}: {v}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 14053,
     "status": "ok",
     "timestamp": 1765045901358,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "dYxswSB8p6nv",
    "outputId": "23484786-5bd5-46b2-e29f-0dbddfe6be23"
   },
   "outputs": [],
   "source": [
    "# RUN TEST\n",
    "test_dir = DATA_PATH / \"raw/SROIE2019/test/img\"\n",
    "files = list(test_dir.glob(\"*.jpg\"))[:2]\n",
    "for f in files: run_scanner(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3106,
     "status": "ok",
     "timestamp": 1765046490355,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "jDvLnSDWEeAl",
    "outputId": "76a644a3-5cf3-4952-aad0-04b331069204"
   },
   "outputs": [],
   "source": [
    "# RUN TEST\n",
    "test_dir = DATA_PATH / \"own\"\n",
    "files = list(test_dir.glob(\"*.jpg\"))[:4]\n",
    "for f in files: run_scanner(f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyODAtLshL8Ly9rZHZ9kbuq4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
