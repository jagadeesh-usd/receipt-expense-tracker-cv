{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title-cell"
   },
   "source": [
    "## Automated Expense Extraction - Receipt Parsing Using YOLO and OCR\n",
    "### Field Extraction from OCR Results\n",
    "\n",
    "**Purpose:** Apply regex patterns to extract structured fields from raw OCR output\n",
    "\n",
    "**Input:** OCR results (JSON files with full_text and lines)\n",
    "\n",
    "**Output:** Extracted fields (CSV: image, vendor, date, total)\n",
    "\n",
    "**Configuration:** Choose which OCR engine(s) to process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19139,
     "status": "ok",
     "timestamp": 1765042200063,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "imports",
    "outputId": "145ac5c1-8f5e-4251-a6fb-330324e5449c"
   },
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    # Mount Google Drive (for Colab)\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Set DATA_PATH for Google Drive\n",
    "    DATA_PATH = Path('/content/drive/MyDrive/data')\n",
    "else:\n",
    "    # Set DATA_PATH for local environment\n",
    "    DATA_PATH = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1765042231569,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "config",
    "outputId": "8d3c87ed-bbb3-4de4-ba1c-87fe9b8f2a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FIELD EXTRACTION CONFIGURATION\n",
      "======================================================================\n",
      "Data Path: ../data\n",
      "\n",
      "OCR Engines to Process: 1\n",
      "  ‚Ä¢ Tesseract\n",
      "\n",
      "Splits: train, test\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION - Choose which OCR engine(s) to process\n",
    "\n",
    "# Set to True to process that OCR engine's results\n",
    "PROCESS_EASYOCR = False      # Extract fields from EasyOCR results\n",
    "PROCESS_TESSERACT = True    # Extract fields from Tesseract results\n",
    "\n",
    "# Splits to process (train, test, or both)\n",
    "SPLITS = [\"train\", \"test\"]\n",
    "\n",
    "# Path Configuration (Auto-configured based on above settings)\n",
    "\n",
    "OCR_ENGINES = []\n",
    "if PROCESS_EASYOCR:\n",
    "    OCR_ENGINES.append({\n",
    "        'name': 'EasyOCR',\n",
    "        'input_dir': DATA_PATH / 'processed/ocr',\n",
    "        'output_dir': DATA_PATH / 'processed/extracted/ocr'\n",
    "    })\n",
    "\n",
    "if PROCESS_TESSERACT:\n",
    "    OCR_ENGINES.append({\n",
    "        'name': 'Tesseract',\n",
    "        'input_dir': DATA_PATH / 'processed/tesseract_ocr',\n",
    "        'output_dir': DATA_PATH / 'processed/extracted/tesseract_ocr'\n",
    "    })\n",
    "\n",
    "# Verify configuration\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FIELD EXTRACTION CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Data Path: {DATA_PATH}\")\n",
    "print(f\"\\nOCR Engines to Process: {len(OCR_ENGINES)}\")\n",
    "for engine in OCR_ENGINES:\n",
    "    print(f\"  ‚Ä¢ {engine['name']}\")\n",
    "print(f\"\\nSplits: {', '.join(SPLITS)}\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "if not OCR_ENGINES:\n",
    "    print(\"‚ö†Ô∏è  WARNING: No OCR engines selected! Set PROCESS_EASYOCR or PROCESS_TESSERACT to True.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "patterns-section"
   },
   "source": [
    "## 2. Regex Patterns & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1765042239278,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "regex-patterns",
    "outputId": "1ad68b95-3ec2-4c53-ce56-6af782f6517a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Regex patterns loaded\n"
     ]
    }
   ],
   "source": [
    "# REGEX PATTERNS\n",
    "\n",
    "# Matches currency-like numbers (e.g., 1,234.56 or 12.50)\n",
    "CURRENCY_NUM_RE = re.compile(r'([0-9]{1,3}(?:[,][0-9]{3})*(?:\\.[0-9]{2})|[0-9]+(?:\\.[0-9]{2}))')\n",
    "\n",
    "# Gap-Tolerant Total Regex\n",
    "# Matches \"Total\", \"Amount\", etc., followed by up to 25 chars of \"noise\", then the number\n",
    "AMOUNT_LABEL_RE = re.compile(\n",
    "    r'(?i)\\b(total|amount|grand total|grand|balance|invoice total|amount due|nett|payable)'\n",
    "    r'(?:[^0-9\\n\\-\\+]{0,25})'  # Allow gap of up to 25 non-digit chars\n",
    "    r'\\s*([0-9,]+\\.\\d{2})'     # The Amount\n",
    ")\n",
    "\n",
    "# Blacklist for vendor guessing (common receipt words to ignore)\n",
    "VENDOR_BLACKLIST = [\n",
    "    \"total\", \"subtotal\", \"amount\", \"gst\", \"tax\", \"invoice\", \"cash\", \"change\",\n",
    "    \"tel\", \"fax\", \"receipt\", \"date\", \"time\", \"document\", \"table\", \"pax\", \"order\",\n",
    "    \"thank\", \"welcome\", \"regards\", \"bill\", \"payment\"\n",
    "]\n",
    "\n",
    "print(\"‚úì Regex patterns loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1765042243262,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "helper-functions",
    "outputId": "18d45122-0d1c-4395-c20d-f64a1d39e874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Helper functions loaded\n"
     ]
    }
   ],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "def normalize_number_str(s: str) -> Optional[float]:\n",
    "    \"\"\"Turn common currency-like strings into float or None.\"\"\"\n",
    "    if not s:\n",
    "        return None\n",
    "    s = s.replace(',', '').strip()\n",
    "    s = re.sub(r'[^0-9\\.\\-]', '', s)  # Remove currency symbols/letters\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def normalize_date_ocr(date_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Heuristic cleanup for common OCR date errors before parsing.\n",
    "    Example: 25/4212018 -> 25/04/2018 (separator glitch)\n",
    "    \"\"\"\n",
    "    if not date_str:\n",
    "        return \"\"\n",
    "    s = date_str.strip()\n",
    "\n",
    "    # Generic Fix: Replace common letter-swaps for numbers\n",
    "    s = s.replace('O', '0').replace('o', '0')\n",
    "    s = s.replace('l', '1').replace('I', '1')\n",
    "\n",
    "    # Specific Fix: Broken separators in OCR (common in SROIE dataset)\n",
    "    if \"/42120\" in s:\n",
    "        s = s.replace(\"/42120\", \"/04/20\")\n",
    "    if \"/420\" in s:\n",
    "        s = s.replace(\"/420\", \"/04/20\")\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def find_date_in_text(full_text: str) -> Optional[str]:\n",
    "    \"\"\"Finds date candidates and tries to parse them into YYYY-MM-DD.\"\"\"\n",
    "    if not full_text:\n",
    "        return None\n",
    "\n",
    "    # Pattern 1: Standard dates (25/04/2018, 2018-04-25, 25.04.18)\n",
    "    date_pattern = re.compile(r'\\b(\\d{1,2}[/\\-\\.]\\d{1,2}[/\\-\\.]\\d{2,4})\\b')\n",
    "    # Pattern 2: Corrupted OCR dates (e.g., 25/4212018 where separators failed)\n",
    "    broken_pattern = re.compile(r'\\b(\\d{1,2}/\\d{5,8})\\b')\n",
    "\n",
    "    # Gather all candidates\n",
    "    candidates = date_pattern.findall(full_text) + broken_pattern.findall(full_text)\n",
    "\n",
    "    for raw in candidates:\n",
    "        clean = normalize_date_ocr(raw)\n",
    "        # Try parsing various common receipt formats\n",
    "        for fmt in (\"%d/%m/%Y\", \"%d-%m-%Y\", \"%d.%m.%Y\",\n",
    "                    \"%d/%m/%y\", \"%d-%m-%y\", \"%Y-%m-%d\"):\n",
    "            try:\n",
    "                dt = datetime.strptime(clean, fmt)\n",
    "                return dt.strftime(\"%Y-%m-%d\")\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_total_in_text(full_text: str) -> Optional[float]:\n",
    "    \"\"\"Finds total amount using Label-First strategy, then Fallback to last number.\"\"\"\n",
    "    if not full_text:\n",
    "        return None\n",
    "\n",
    "    # 1. Label-based search (Best accuracy)\n",
    "    matches = list(AMOUNT_LABEL_RE.finditer(full_text))\n",
    "    if matches:\n",
    "        # Use the last labeled total found (usually the Grand Total at bottom)\n",
    "        for m in reversed(matches):\n",
    "            val = m.group(2)\n",
    "            num = normalize_number_str(val)\n",
    "            if num is not None:\n",
    "                return num\n",
    "\n",
    "    # 2. Fallback: Last currency-formatted number in text\n",
    "    # (Useful if the word \"Total\" is missing or OCR failed on the label)\n",
    "    nums = CURRENCY_NUM_RE.findall(full_text)\n",
    "    if nums:\n",
    "        val = nums[-1]\n",
    "        return normalize_number_str(val)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def guess_vendor_from_lines(lines: List[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Generic heuristic to find vendor name.\n",
    "    Returns the first line that looks like a name (has letters) and isn't blacklisted.\n",
    "    \"\"\"\n",
    "    if not lines:\n",
    "        return None\n",
    "\n",
    "    # Check only the top header section (first 8 lines)\n",
    "    for line in lines[:8]:\n",
    "        line = line.strip()\n",
    "        if len(line) < 3:\n",
    "            continue  # Skip tiny noise\n",
    "\n",
    "        low = line.lower()\n",
    "\n",
    "        # Skip blacklisted generic words (Receipt, Tax Invoice, etc.)\n",
    "        if any(b in low for b in VENDOR_BLACKLIST):\n",
    "            continue\n",
    "\n",
    "        # If line contains letters, it's likely the Vendor Name\n",
    "        if any(c.isalpha() for c in line):\n",
    "            return line\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_fields_from_ocr_result(ocr_result: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Main extraction function.\n",
    "    Takes OCR result dict and returns extracted vendor, date, total.\n",
    "    \"\"\"\n",
    "    full_text = (ocr_result.get(\"full_text\") or \"\").strip()\n",
    "    lines = ocr_result.get(\"lines\") or []\n",
    "\n",
    "    vendor = guess_vendor_from_lines(lines)\n",
    "    date = find_date_in_text(full_text)\n",
    "    total = find_total_in_text(full_text)\n",
    "\n",
    "    return {\n",
    "        \"vendor\": vendor,\n",
    "        \"date\": date,\n",
    "        \"total\": total,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úì Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "extraction-section"
   },
   "source": [
    "## 3. Field Extraction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1765042250027,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "extraction-pipeline",
    "outputId": "0191da20-87a2-42dd-b5a0-0821d681989d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Extraction pipeline ready\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTION PIPELINE\n",
    "\n",
    "def process_ocr_engine(engine_config: dict, splits: List[str]):\n",
    "    \"\"\"\n",
    "    Process one OCR engine's results across multiple splits.\n",
    "\n",
    "    Args:\n",
    "        engine_config: Dict with 'name', 'input_dir', 'output_dir'\n",
    "        splits: List of splits to process (e.g., ['train', 'test'])\n",
    "    \"\"\"\n",
    "    engine_name = engine_config['name']\n",
    "    input_dir = engine_config['input_dir']\n",
    "    output_dir = engine_config['output_dir']\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Processing: {engine_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Input:  {input_dir}\")\n",
    "    print(f\"Output: {output_dir}\")\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    total_processed = 0\n",
    "\n",
    "    for split in splits:\n",
    "        src_dir = input_dir / split\n",
    "        out_csv = output_dir / f\"{split}_extracted.csv\"\n",
    "\n",
    "        if not src_dir.exists():\n",
    "            print(f\"\\n‚ö†Ô∏è  {split}: Directory not found: {src_dir}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüìÇ Processing {split}...\")\n",
    "\n",
    "        rows = []\n",
    "        json_files = sorted(src_dir.glob(\"*.json\"))\n",
    "\n",
    "        if not json_files:\n",
    "            print(f\"   ‚ö†Ô∏è  No JSON files found in {src_dir}\")\n",
    "            continue\n",
    "\n",
    "        # Process each OCR result\n",
    "        for jfile in json_files:\n",
    "            try:\n",
    "                with open(jfile, \"r\", encoding=\"utf-8\") as f:\n",
    "                    ocr_result = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Failed to read {jfile.name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Extract fields\n",
    "            extracted = extract_fields_from_ocr_result(ocr_result)\n",
    "\n",
    "            rows.append({\n",
    "                \"image\": jfile.stem,\n",
    "                \"vendor\": extracted.get(\"vendor\"),\n",
    "                \"date\": extracted.get(\"date\"),\n",
    "                \"total\": extracted.get(\"total\")\n",
    "            })\n",
    "\n",
    "        # Write to CSV\n",
    "        with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvf:\n",
    "            writer = csv.DictWriter(csvf, fieldnames=[\"image\", \"vendor\", \"date\", \"total\"])\n",
    "            writer.writeheader()\n",
    "            for row in rows:\n",
    "                writer.writerow(row)\n",
    "\n",
    "        print(f\"   ‚úì Saved: {out_csv}\")\n",
    "        print(f\"   ‚úì Records: {len(rows)}\")\n",
    "        total_processed += len(rows)\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{engine_name} Complete: {total_processed} total records processed\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "\n",
    "print(\"‚úì Extraction pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run-section"
   },
   "source": [
    "## 4. Run Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21749,
     "status": "ok",
     "timestamp": 1765042276672,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "run-extraction",
    "outputId": "6410fc98-f1c8-4b5e-bb52-e4a612ce8433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# STARTING FIELD EXTRACTION\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "Processing: Tesseract\n",
      "======================================================================\n",
      "Input:  ../data/processed/tesseract_ocr\n",
      "Output: ../data/processed/extracted/tesseract_ocr\n",
      "\n",
      "üìÇ Processing train...\n",
      "   ‚úì Saved: ../data/processed/extracted/tesseract_ocr/train_extracted.csv\n",
      "   ‚úì Records: 626\n",
      "\n",
      "üìÇ Processing test...\n",
      "   ‚úì Saved: ../data/processed/extracted/tesseract_ocr/test_extracted.csv\n",
      "   ‚úì Records: 347\n",
      "\n",
      "======================================================================\n",
      "Tesseract Complete: 973 total records processed\n",
      "======================================================================\n",
      "\n",
      "######################################################################\n",
      "# EXTRACTION COMPLETE\n",
      "######################################################################\n",
      "\n",
      "‚úÖ Processed 1 OCR engine(s)\n",
      "‚úÖ Output saved to: ../data/processed/extracted\n"
     ]
    }
   ],
   "source": [
    "# RUN EXTRACTION FOR ALL CONFIGURED ENGINES\n",
    "\n",
    "if not OCR_ENGINES:\n",
    "    print(\"‚ùå No OCR engines configured. Please set PROCESS_EASYOCR or PROCESS_TESSERACT to True.\")\n",
    "else:\n",
    "    print(\"\\n\" + \"#\"*70)\n",
    "    print(\"# STARTING FIELD EXTRACTION\")\n",
    "    print(\"#\"*70)\n",
    "\n",
    "    for engine_config in OCR_ENGINES:\n",
    "        try:\n",
    "            process_ocr_engine(engine_config, SPLITS)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error processing {engine_config['name']}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    print(\"\\n\" + \"#\"*70)\n",
    "    print(\"# EXTRACTION COMPLETE\")\n",
    "    print(\"#\"*70)\n",
    "    print(f\"\\n‚úÖ Processed {len(OCR_ENGINES)} OCR engine(s)\")\n",
    "    print(f\"‚úÖ Output saved to: {DATA_PATH / 'processed/extracted'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-section"
   },
   "source": [
    "## 5. Summary & Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1765042312951,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "summary",
    "outputId": "48da574e-c7aa-4247-9ad5-f0b15ecdaf25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXTRACTION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Tesseract:\n",
      "  ‚Ä¢ train: 626 records ‚Üí ../data/processed/extracted/tesseract_ocr/train_extracted.csv\n",
      "  ‚Ä¢ test: 347 records ‚Üí ../data/processed/extracted/tesseract_ocr/test_extracted.csv\n",
      "\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Field extraction complete!\n",
      "\n",
      "Next steps:\n",
      "  1. Use these extracted fields for evaluation\n",
      "  2. Compare against ground truth to calculate accuracy\n"
     ]
    }
   ],
   "source": [
    "# SUMMARY\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXTRACTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for engine_config in OCR_ENGINES:\n",
    "    engine_name = engine_config['name']\n",
    "    output_dir = engine_config['output_dir']\n",
    "\n",
    "    print(f\"\\n{engine_name}:\")\n",
    "\n",
    "    for split in SPLITS:\n",
    "        csv_file = output_dir / f\"{split}_extracted.csv\"\n",
    "\n",
    "        if csv_file.exists():\n",
    "            # Count rows\n",
    "            with open(csv_file, 'r', encoding='utf-8') as f:\n",
    "                row_count = sum(1 for line in f) - 1  # Subtract header\n",
    "\n",
    "            print(f\"  ‚Ä¢ {split}: {row_count} records ‚Üí {csv_file}\")\n",
    "        else:\n",
    "            print(f\"  ‚Ä¢ {split}: ‚ùå Not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\n‚úÖ Field extraction complete!\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(\"  1. Use these extracted fields for evaluation\")\n",
    "print(\"  2. Compare against ground truth to calculate accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sample-section"
   },
   "source": [
    "## 6. Sample Output Preview (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1765042322877,
     "user": {
      "displayName": "Jagadeesh Sellappan",
      "userId": "07215682532086792256"
     },
     "user_tz": -330
    },
    "id": "sample-preview",
    "outputId": "a46c960f-4b96-4a94-91be-06081ef68aed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAMPLE EXTRACTED FIELDS\n",
      "======================================================================\n",
      "\n",
      "Tesseract - Test Set (first 5 records):\n",
      "----------------------------------------------------------------------\n",
      "          image                               vendor        date   total\n",
      "0  X00016469670                         tan chay yee         NaN  193.00\n",
      "1  X00016469671                         tan chay yee  2019-01-02  170.00\n",
      "2  X51005200931                               fore 2         NaN   24.69\n",
      "3  X51005230605  : 03-6156 8757 Co No: 001083069-M 4  2018-02-01    1.90\n",
      "4  X51005230616     Gerbang Alaf Restaurants Sdn Bhd  2018-01-18   38.90\n",
      "\n",
      "Statistics:\n",
      "  Total records: 347\n",
      "  Vendor extracted: 345 (99.4%)\n",
      "  Date extracted: 231 (66.6%)\n",
      "  Total extracted: 341 (98.3%)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW SAMPLE RESULTS\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE EXTRACTED FIELDS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for engine_config in OCR_ENGINES:\n",
    "    engine_name = engine_config['name']\n",
    "    output_dir = engine_config['output_dir']\n",
    "\n",
    "    # Show sample from test set\n",
    "    csv_file = output_dir / \"test_extracted.csv\"\n",
    "\n",
    "    if csv_file.exists():\n",
    "        print(f\"\\n{engine_name} - Test Set (first 5 records):\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        df = pd.read_csv(csv_file)\n",
    "        print(df.head())\n",
    "\n",
    "        # Statistics\n",
    "        print(f\"\\nStatistics:\")\n",
    "        print(f\"  Total records: {len(df)}\")\n",
    "        print(f\"  Vendor extracted: {df['vendor'].notna().sum()} ({df['vendor'].notna().sum()/len(df)*100:.1f}%)\")\n",
    "        print(f\"  Date extracted: {df['date'].notna().sum()} ({df['date'].notna().sum()/len(df)*100:.1f}%)\")\n",
    "        print(f\"  Total extracted: {df['total'].notna().sum()} ({df['total'].notna().sum()/len(df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"\\n{engine_name}: No test results found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
