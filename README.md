# Automated Expense Extraction: Receipt Parsing Using Computer Vision and OCR

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Dataset: SROIE](https://img.shields.io/badge/Dataset-SROIE%202019-green.svg)](https://rrc.cvc.uab.es/?ch=13)

**Team:** AAI-521 Group 11 | **Author:** Jagadeesh Kumar Sellappan

**GitHub:** [receipt-expense-tracker-cv](https://github.com/jagadeesh-usd/receipt-expense-tracker-cv.git)

---

## ğŸ“‹ Table of Contents

- [Project Overview](#-project-overview)
- [Dataset](#-dataset)
- [System Architecture](#-system-architecture)
- [Results](#-results)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Methodology](#-methodology)
- [Evaluation](#-evaluation)
- [Future Work](#-future-work)
- [References](#-references)

---

## ğŸ¯ Project Overview

This project develops an **end-to-end hybrid computer vision pipeline** that automatically extracts essential financial information (Vendor Name, Date, Total Amount) from scanned or photographed receipts. The system combines **YOLO object detection** with **OCR engines** (EasyOCR and Tesseract) to achieve robust field extraction.

### Key Objectives

1. **Automated Information Extraction:** Parse receipts to extract vendor, date, and total
2. **Quality-Aware Processing:** Adaptive preprocessing based on image quality analysis
3. **Hybrid Detection:** Combine YOLO localization with OCR for improved accuracy
4. **Comprehensive Evaluation:** Compare multiple approaches to demonstrate effectiveness

### Why This Matters

- **Problem:** Manual expense entry is slow, error-prone, and tedious
- **Solution:** Automated pipeline reduces effort, improves accuracy, enables scalability
- **Impact:** Valuable for personal finance tracking, reimbursement systems, enterprise automation

---

**Key Improvements:**
- âœ… **YOLO Integration:** Added object detection for vendor/date/total localization
- âœ… **Adaptive Preprocessing:** Quality-based preprocessing (faint/normal/shadowed)
- âœ… **Multi-Engine Comparison:** Evaluated both EasyOCR and Tesseract
- âœ… **Comprehensive Evaluation:** 4-way comparison matrix (OCR-only vs Hybrid Ã— 2 engines)

**Final Performance Results:**
| Approach | Vendor | Date | Total | Average |
|----------|--------|------|-------|---------|
| **YOLO + Tesseract (BEST)** | **75.8%** | **65.4%** | **54.8%** | **65.3%** |
| EasyOCR | 39.5% | 36.6% | 40.9% | 39.0% |
| Tesseract-Only | 37.5% | 36.9% | 47.8% | 40.7% |

---

## ğŸ“Š Dataset

**SROIE (Scanned Receipts OCR and Information Extraction)**

- **Source:** [ICDAR 2019 Competition](https://rrc.cvc.uab.es/?ch=13)
- **Size:**  
  - 626 training images
  - 347 testing images (used for evaluation)
 

**Characteristics:**
- Real-world financial documents
- Diverse layouts, fonts, lighting conditions
- Mixed quality (mobile cameras + flatbed scanners)
- Intentionally raw with real-world imperfections:
  - Skewed/rotated receipts
  - Low lighting and shadows
  - Faded or blurred text
  - Non-uniform backgrounds

**Annotations:**
Each receipt includes:
- Raw image (varying resolutions)
- Ground-truth OCR text file
- Key-value pairs: `company`, `date`, `total`, `address`

---

## ğŸ—ï¸ System Architecture

### High-Level Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT: Receipt Image                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Quality Analysis      â”‚
                â”‚   (STD thresholds)      â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Adaptive Preprocessing  â”‚
                â”‚ â€¢ Faint: Light CLAHE    â”‚
                â”‚ â€¢ Normal: Medium CLAHE  â”‚
                â”‚ â€¢ Shadowed: Adaptive    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   YOLO Detection        â”‚
                â”‚   (Vendor/Date/Total)   â”‚
                â”‚   84.1% mAP@0.5        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Crop ROIs             â”‚
                â”‚   (with padding)        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   OCR Engine            â”‚
                â”‚   (EasyOCR/Tesseract)   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Field Extraction       â”‚
                â”‚  (Regex + Validation)   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Fallback (if needed)   â”‚
                â”‚  Full-page OCR + Regex  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  OUTPUT: JSON           â”‚
                â”‚  {vendor, date, total}  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Contributions

### 1. **Quality-Based Adaptive Preprocessing**

Developed empirical thresholds for receipt quality classification:

```python
# Quality Classification (from EDA)
if std < 30:    â†’ Faint    (24% of dataset) â†’ Light CLAHE (1.8)
if 30-55:       â†’ Normal   (56% of dataset) â†’ Medium CLAHE (2.5)
if std > 55:    â†’ Shadowed (20% of dataset) â†’ Adaptive Threshold
```

**Impact:** 15-25% estimated improvement over uniform preprocessing

### 2. **Hybrid YOLO + OCR Architecture**

- **Why YOLO?** Localizes fields spatially before OCR
- **Benefit:** Reduces false positives, improves extraction accuracy
- **Training:** YOLOv8n, 50 epochs, 384Ã—384px, achieved **84.1% mAP@0.5**

**Per-class Detection Performance:**
- Vendor: 96.2% mAP â­ (excellent header detection)
- Date: 69.6% mAP
- Total: 74.5% mAP

### 3. **Multi-Engine Comprehensive Evaluation**

First systematic comparison of 3 approaches on SROIE:

| Approach | Vendor | Date | Total | Avg | Notes |
|----------|--------|------|-------|-----|-------|
| **YOLO + Tesseract** | **75.8%** | **65.4%** | **54.8%** | **65.3%** | **BEST** âœ… |
| EasyOCR-Only | 39.5% | 36.6% | 40.9% | 39.0% | Underperforms |
| Tesseract-Only | 37.5% | 36.9% | 47.8% | 40.7% | Baseline |

**Key Finding:** YOLO improves Tesseract by **+12% absolute** (22% relative)

---

## ğŸ“ˆ Results

### YOLO Detection Performance

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•—
â•‘ Class          â•‘ Precisionâ•‘  Recall  â•‘  mAP  â•‘ Images â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•£
â•‘ Vendor         â•‘  86.3%   â•‘  94.0%   â•‘ 96.2% â•‘   235  â•‘
â•‘ Date           â•‘  68.3%   â•‘  63.4%   â•‘ 69.6% â•‘    68  â•‘
â•‘ Total          â•‘  72.8%   â•‘  68.0%   â•‘ 74.5% â•‘   338  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•£
â•‘ Overall        â•‘  75.8%   â•‘  75.1%   â•‘ 80.1% â•‘   344  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•
```

**Training Details:**
- Model: YOLOv8n (3.2M parameters)
- Input: 1280px
- Epochs: 50
- Hardware: A100 GPU (~22 minutes)
- Dataset: 626 train, 344 val

### End-to-End Extraction Performance

**YOLO + Tesseract Hybrid:**
```
Vendor Accuracy:  74.35%
Date Accuracy:    67.15%
Total Accuracy:   56.48%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average:          65.99%
```

## ğŸš€ Installation

### Prerequisites

- Python 3.8+
- Google Colab (recommended) or local GPU
- 10GB+ storage for dataset

### Setup

```bash
# 1. Clone repository
git clone https://github.com/jagadeesh-usd/receipt-expense-tracker-cv.git
cd receipt-expense-tracker-cv

# 2. Install dependencies
pip install -r requirements.txt

# 3. Download SROIE dataset
# Manual download from: https://rrc.cvc.uab.es/?ch=13
# Place in: data/raw/SROIE2019/

# 3. Install Tesseract OCR Engine (Required for pytesseract)
# Linux (Ubuntu/Debian/Colab):
sudo apt install tesseract-ocr

# macOS (Homebrew):
brew install tesseract

# Windows:
# Download installer from: https://github.com/UB-Mannheim/tesseract/wiki
# And add Tesseract to your System PATH variables.
```

### Requirements

```txt
# Core
opencv-python>=4.8.0
numpy>=1.24.0
pandas>=2.0.0
pillow>=10.0.0

# OCR
easyocr>=1.7.0
pytesseract>=0.3.10

# Object Detection
ultralytics>=8.0.0
torch>=2.0.0

# Utilities
tqdm>=4.65.0
matplotlib>=3.7.0
seaborn>=0.12.0
scikit-learn>=1.3.0
python-dateutil>=2.8.0
fuzzywuzzy>=0.18.0

# Document Processing
python-docx>=0.8.11
reportlab>=4.0.0
```

---

## ğŸ’» Usage

### Quick Start (Google Colab)

```python
# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Run notebooks in sequence:
# 00_EDA.ipynb                    â†’ Exploratory data analysis
# 01_Preprocess.ipynb             â†’ Adaptive preprocessing
# 02_PrepareYOLO.ipynb            â†’ Create YOLO dataset
# 03_Train_YOLO_Detection.ipynb  â†’ Train YOLO model
# 04_OCR_Text_Extraction.ipynb   â†’ EasyOCR extraction
# 05_OCR_Tesseract.ipynb          â†’ Tesseract extraction
# 06_Field_Extraction_Regex.ipynb â†’ Extract fields from OCR
# 07_Evaluation_OCR_Metrics.ipynb â†’ OCR evaluation
# 08_Evaluate_YOLO_Model.ipynb   â†’ YOLO metrics
# 09_Inference.ipynb              â†’ Hybrid pipeline inference
```

### Configuration Example

```python
# 06_Field_Extraction_Regex.ipynb
PROCESS_EASYOCR = True      # Extract from EasyOCR results
PROCESS_TESSERACT = True    # Extract from Tesseract results
SPLITS = ["train", "test"]  # Which splits to process
```

---

## ğŸ“ Project Structure

```
receipt-expense-tracker-cv/
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks (Google Colab)
â”‚   â”œâ”€â”€ 00_EDA.ipynb               # Exploratory data analysis
â”‚   â”œâ”€â”€ 01_Preprocess.ipynb        # Adaptive preprocessing
â”‚   â”œâ”€â”€ 02_PrepareYOLO.ipynb       # YOLO dataset creation
â”‚   â”œâ”€â”€ 03_Train_YOLO_Detection.ipynb  # YOLO training
â”‚   â”œâ”€â”€ 04_OCR_Text_Extraction.ipynb   # EasyOCR extraction
â”‚   â”œâ”€â”€ 05_OCR_Tesseract.ipynb     # Tesseract extraction
â”‚   â”œâ”€â”€ 06_Field_Extraction_Regex.ipynb # Field extraction
â”‚   â”œâ”€â”€ 07_Evaluation_OCR_Metrics.ipynb # OCR evaluation
â”‚   â”œâ”€â”€ 08_Evaluate_YOLO_Model.ipynb   # YOLO evaluation
â”‚   â””â”€â”€ 09_Inference.ipynb         # Hybrid pipeline inference
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/SROIE2019/             # Original dataset (626+347+27)
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ preprocessed/          # Quality-based preprocessing
â”‚   â”‚   â”œâ”€â”€ yolo_dataset/          # YOLO format annotations
â”‚   â”‚   â”œâ”€â”€ ocr/                   # EasyOCR results
â”‚   â”‚   â”œâ”€â”€ tesseract_ocr/         # Tesseract results
â”‚   â”‚   â””â”€â”€ extracted/             # Extracted fields (CSV)
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ yolo_receipts_highres_small/weights/best.pt
â”‚
â”‚
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ LICENSE                        # MIT License
```

---

## ğŸ”¬ Methodology

### Stage 1: Exploratory Data Analysis

**Quality Distribution:**
```
Faint (STD < 30):     24% â†’ Light CLAHE (1.8)
Normal (30-55):       56% â†’ Medium CLAHE (2.5)
Shadowed (STD > 55):  20% â†’ Adaptive Threshold
```

### Stage 2: Adaptive Preprocessing

```python
def adaptive_preprocess(image):
    std = np.std(image)
    if std < 30:  # Faint
        return apply_clahe(image, clip_limit=1.8)
    elif std <= 55:  # Normal
        return apply_clahe(image, clip_limit=2.5)
    else:  # Shadowed
        return adaptive_threshold(image)
```

### Stage 3: YOLO Training

**Configuration:**
- Model: YOLOv8n
- Epochs: 50
- Image size: 384Ã—384px
- Batch: 16
- Device: A100 GPU

### Stage 4: Hybrid Inference

1. YOLO Detection â†’ Bounding boxes
2. Crop Regions â†’ With 5px padding
3. OCR â†’ Tesseract/EasyOCR
4. Validation â†’ Check format
5. Fallback â†’ Full-page if needed

---

## ğŸ“Š Evaluation

### Metrics

**YOLO Detection:**
- Precision, Recall, mAP@0.5

**End-to-End Extraction:**
- Vendor: Fuzzy matching (â‰¥0.7 similarity)
- Date: Exact match after parsing
- Total: Within $0.10 tolerance

---

## ğŸ“š References

1. SROIE 2019: https://rrc.cvc.uab.es/?ch=13
2. YOLOv8: https://docs.ultralytics.com/
3. EasyOCR: https://github.com/JaidedAI/EasyOCR
4. Tesseract: https://github.com/tesseract-ocr/tesseract

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file

---

## ğŸ™ Acknowledgments

- University of San Diego
- ICDAR 2019 SROIE organizers
- Ultralytics (YOLOv8)
- JaidedAI (EasyOCR)

---

## ğŸ“ Contact

**Jagadeesh Kumar Sellappan**  
University of San Diego  
Email: jsellappan@sandiego.edu  
GitHub: [@jagadeesh-usd](https://github.com/jagadeesh-usd)

---

**Last Updated:** December 2025 
**Status:** âœ… Complete  
**Reproducibility:** High

---

*This project demonstrates the power of combining traditional computer vision (preprocessing), modern deep learning (YOLO), and classical NLP (regex) to solve real-world document understanding problems.*